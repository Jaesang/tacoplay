---

# Make sure ceph-ansible/site.yml exists
- hosts: localhost
  any_errors_fatal: "{{ any_errors_fatal | default(true) }}"
  tasks:
    - name: copy site.yml
      copy:
        src: "{{ playbook_dir }}/ceph-ansible/site.yml.sample"
        dest: "{{ playbook_dir }}/ceph-ansible/site.yml"
  tags: always

# Assert inventory
- import_playbook: site-assert.yml
  tags: assert

- hosts: localhost:all
  any_errors_fatal: "{{ any_errors_fatal | default(true) }}"
  tasks:
    - name: include global override files
      include_vars: "{{ item }}"
      loop:
        - "{{ playbook_dir }}/vars/global_taco.yml"
        - "{{ playbook_dir }}/vars/global_docker.yml"
        - "{{ playbook_dir }}/vars/global_ceph.yml"
        - "{{ playbook_dir }}/vars/global_k8s-cluster.yml"
        - "{{ playbook_dir }}/vars/site_specific.yml"

    - name: include global override files
      include_vars: "{{ item }}"
      loop:
        - "{{ playbook_dir }}/vars/global_k8s-images.yml"
      when: localrepo_enabled
  tags: always

# Populate hostname to hosts file
- hosts: taco
  any_errors_fatal: "{{ any_errors_fatal | default(true) }}"
  tasks:
    - name: make sure hostname is in hosts file
      replace:
        dest: /etc/hosts
        regexp: '^(127\.0\.0\.1(?!.*\b{{ inventory_hostname }}\b).*)$'
        replace: '\1 {{ inventory_hostname }}'
  tags: always

# Enable registry.cicd.stg.taco
- hosts: taco
  any_errors_fatal: "{{ any_errors_fatal | default(true) }}"
  tasks:
    - name: registry.cicd.stg.taco | populate custom entries into hosts file
      lineinfile:
        path: /etc/hosts
        line: 192.168.54.30 registry.cicd.stg.taco
        state: present
      when: cicd_registry_enabled|default(false)

    - name: registry.cicd.stg.taco | create directory for cert
      file:
        path: /etc/docker/certs.d/registry.cicd.stg.taco
        state: directory
      when: cicd_registry_enabled|default(false)

    - name: registry.cicd.stg.taco | create cert file
      copy:
        src: "registry-certs"
        dest: "/etc/docker/certs.d/registry.cicd.stg.taco/ca.crt"
      when: cicd_registry_enabled|default(false)
  tags: always

# Populate registry hosts into hosts file
- hosts: taco
  any_errors_fatal: "{{ any_errors_fatal | default(true) }}"
  tasks:
    - name: populate taco registry into hosts file
      blockinfile:
        dest: /etc/hosts
        block: |-
          {% for item in (groups['registry']|default([]))|unique -%}{{ hostvars[item]['ip'] }} {{ item }}
          {% endfor %}
        state: present
        create: yes
        backup: yes
        marker: "# TACO registry hosts {mark}"
  tags: always

# Prepare OS for TACO
- hosts: taco
  any_errors_fatal: "{{ any_errors_fatal | default(true) }}"
  roles:
    - { role: taco-defaults }
    - { role: setup-os }
  tags: setup-os

# Run docker registry
- hosts: registry
  any_errors_fatal: "{{ any_errors_fatal | default(true) }}"
  roles:
    - { role: taco-defaults }
    - { role: docker }
    - { role: docker-registry }
  tags: registry

# Copy ceph.repo to repository when custom repo is used
# It assumes registry and repository hosts are the same
- hosts: registry
  any_errors_fatal: "{{ any_errors_fatal | default(true) }}"
  tasks:
    - name: copy ceph.repo to local repository
      copy:
        src: "{{ inventory_dir }}/ceph.repo"
        dest: "{{ ceph_repository_dir }}/ceph.repo"
      when: ceph_repository_enabled|default(false)
  tags: ceph

# Install Ceph
- import_playbook: ceph-ansible/site.yml
  tags: ceph

# TODO: add tests for checking status of the new ceph cluster

# Install K8S
- import_playbook: kubespray/cluster.yml
  tags: k8s

- hosts: taco
  roles:
    - { role: taco-defaults }
    - { role: admin-node }
  tags: k8s

- hosts: admin-node
  any_errors_fatal: "{{ any_errors_fatal | default(true) }}"
  roles:
    - { role: taco-defaults }
    - { role: rbd_provisioner, when: rbd_provisioner_enabled }
  tags: k8s

# TODO: add tests for checking status of the new k8s cluster

# Create K8S resources required for deploying OpenStack
- hosts: admin-node
  any_errors_fatal: "{{ any_errors_fatal | default(true) }}"
  roles:
    - { role: taco-defaults }
    - { role: openstack/preinstall }
  tags: openstack 

# Make admin-node ready for armada apply
- hosts: admin-node
  any_errors_fatal: "{{ any_errors_fatal | default(true) }}"
  roles:
    - { role: taco-defaults }
    - { role: armada }
  tags: armada

- hosts: admin-node:controller-node
  any_errors_fatal: "{{ any_errors_fatal | default(true) }}"
  roles:
    - { role: taco-defaults }
    - { role: openstack/client }
  tasks:
    - name: check host where ingress controller is running
      shell: >-
        {{ bin_dir }}/kubectl get po -n openstack -o wide |
        grep "^ingress-[^error]" |
        awk '{print $6}'
      retries: 10
      delay: 10
      register: ingress_host
      until: ingress_host.stdout != ""
      become: no
      delegate_to: "{{ groups['admin-node']|first }}"
      when: auto_release_enabled|default(true)

    - fail:
        msg: "ingress controller is not running"
      when: auto_release_enabled|default(true) and ingress_host.stdout == ""

    - name: update hosts file for openstack services access via ingress
      blockinfile:
        path: /etc/hosts
        block: |
          {{ ingress_host.stdout }} keystone.openstack.svc.cluster.local
          {{ ingress_host.stdout }} glance.openstack.svc.cluster.local
          {{ ingress_host.stdout }} nova.openstack.svc.cluster.local
          {{ ingress_host.stdout }} neutron.openstack.svc.cluster.local
          {{ ingress_host.stdout }} cinder.openstack.svc.cluster.local
        state: present
        marker: "# OPENSTACK SERVICES {mark}"
      when: auto_release_enabled|default(true)
  tags: openstack
