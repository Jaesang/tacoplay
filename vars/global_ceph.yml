ceph_stable_release: luminous
ceph_origin: repository
ceph_repository: >-
  {%- if localrepo_enabled -%}custom{%- else -%}community{%- endif -%}
ceph_custom_repo: "http://{{ localrepo_yum }}/ceph/ceph.repo"
ceph_mirror: http://hk.ceph.com

ntp_service_enabled: false
copy_admin_key: >-
  {%- if (groups["mons"]|length>0) -%}true{%- else -%}false{%- endif -%}
ceph_mgr_modules: [status,dashboard,prometheus]

ceph_conf_overrides:
  global:
    mon_allow_pool_delete: true
    osd_pool_default_size: 2
    osd_pool_default_min_size: 1
    osd_pg_stat_report_internal_max: 1

    filestore_wbthrottle_enable: false
    filestore_wbthrottle_xfs_bytes_start_flusher: 2147483648
    filestore_wbthrottle_xfs_bytes_hard_limit: 2147484000
    filestore_wbthrottle_xfs_ios_start_flusher: 80000
    filestore_wbthrottle_xfs_ios_hard_limit: 140000
    filestore_wbthrottle_xfs_inodes_start_flusher: 10000

    filestore_queue_max_bytes: 1048576000
    filestore_queue_max_ops: 8000
    filestore_max_sync_interval: 10
    filestore_fd_cache_size: 131072
    filestore_fd_cache_shards: 32
    filestore_op_threads: 20
    filestore_omap_header_cache_size: 5000000
    journal_max_write_entries: 2000
    journal_max_write_bytes: 4194304000

    osd_client_message_size_cap: 0
    osd_client_message_cap: 0
    objecter_inflight_ops: 102400
    objecter_inflight_op_bytes: 1048576000
    ms_dispatch_throttle_bytes: 1048576000

    #osd_op_threads: 32
    osd_op_num_shards: 8
    osd_op_num_threads_per_shard: 2

    mon_pg_warn_max_object_skew: 10000
    mon_pg_warn_min_per_osd: 0
    #mon_pg_warn_max_per_osd: 32768
    #mon_compat_on_trim: false
    mon_max_pool_pg_num: 166496
    mon_osd_max_split_count: 10000
    osd_pg_object_context_cache_count: 512

    leveldb_write_buffer_size: 134217728
    leveldb_cache_size: 536870912
    leveldb_compression: false

osd_scenario: lvm

kube_pool:
  name: "kube"
  pg_num: "{{ kube_pool_pg['pg_num'] }}"
  pgp_num: "{{ kube_pool_pg['pgp_num'] }}"
  rule_name: "replicated_rule"
  type: 1
  erasure_profile: ""
  expected_num_objects: ""
  application: "rbd"
openstack_glance_pool:
  name: "images"
  pg_num: "{{ glance_pool_pg['pg_num'] }}"
  pgp_num: "{{ glance_pool_pg['pgp_num'] }}"
  rule_name: "replicated_rule"
  type: 1
  erasure_profile: ""
  expected_num_objects: ""
openstack_cinder_pool:
  name: "volumes"
  pg_num: "{{ cinder_pool_pg['pg_num'] }}"
  pgp_num: "{{ cinder_pool_pg['pgp_num'] }}"
  rule_name: "replicated_rule"
  type: 1
  erasure_profile: ""
  expected_num_objects: ""
openstack_cinder_backup_pool:
  name: "backups"
  pg_num: "{{ cinder_backup_pool_pg['pg_num'] }}"
  pgp_num: "{{ cinder_backup_pool_pg['pgp_num'] }}"
  rule_name: "replicated_rule"
  type: 1
  erasure_profile: ""
  expected_num_objects: ""

openstack_pools:
  - "{{ kube_pool }}"
  - "{{ openstack_glance_pool }}"
  - "{{ openstack_cinder_pool }}"
  - "{{ openstack_cinder_backup_pool }}"

openstack_keys:
  - { name: client.kube, caps: { mon: "profile rbd", osd: "profile rbd pool=kube"}, key: "AQAPn8tUmPBwCxAAeIfvpDKA1fGvrBeXGdc6xQ==", mode: "0600" }
  - { name: client.cinder, caps: { mon: "profile rbd", osd: "profile rbd pool=volumes, profile rbd pool=backups, profile rbd pool=images"}, key: "AQAin8tU0CFgEhAATb7sYgtWsh+S5HEbg6MrGg==",  mode: "0600" }
